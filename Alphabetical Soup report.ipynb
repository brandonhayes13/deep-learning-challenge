{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alphabetical Soup Report\n",
    "## Overview of the Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this analysis was to create a deep learning model to predict the success of charitable organizations in securing funding. The dataset contained information about different organizations, including their name, application type, and classification. The task was to predict whether the organization was successful in securing funding or not.\n",
    "Results\n",
    "\n",
    "Data Preprocessing\n",
    "\n",
    "•\tTarget Variable(s):\n",
    "o\tThe target variable for the model is IS_SUCCESSFUL, which indicates whether an organization was successful (1) or not successful (0) in securing funding.\n",
    "\n",
    "•\tFeature Variables:\n",
    "o\tThe features used to make predictions include:\n",
    "\tNAME: The organization's name.\n",
    "\tAPPLICATION_TYPE: The type of application.\n",
    "\tCLASSIFICATION: The classification of the organization.\n",
    "\tOther features include AFFILIATION, USE_CASE, and ORGANIZATION_TYPE.\n",
    "\n",
    "•\tVariables to Remove:\n",
    "o\tThe EIN column was removed as it didn’t provide useful information for predicting success.\n",
    "\n",
    "Compiling, Training, and Evaluating the Model\n",
    "\n",
    "•\tModel Architecture:\n",
    "o\tThe neural network had the following structure:\n",
    "\tFirst Hidden Layer: 128 neurons, with a ReLU activation function.\n",
    "\tSecond Hidden Layer: 64 neurons, with a ReLU activation function.\n",
    "\tThird Hidden Layer: 32 neurons, with a ReLU activation function.\n",
    "\tOutput Layer: 1 neuron with a sigmoid activation function to output a value between 0 and 1 (indicating success or failure).\n",
    "\n",
    "o\tReason for Choosing This Architecture:\n",
    "\tI chose this structure based on common practice for binary classification. The first layer had the most neurons to capture patterns, and the layers gradually reduced in size to simplify the model. ReLU was used because it helps the model learn more efficiently.\n",
    "\n",
    "•\tModel Performance:\n",
    "o\tThe model achieved an accuracy of 79% on the test data. This is a decent result, but it indicates that there is still room for improvement.\n",
    "\n",
    "•\tSteps taken to Improve the Model:\n",
    "o\tI trained the model for 150 epochs to give it enough time to learn from the data.\n",
    "o\tI replaced categories with fewer than 5 occurrences with the label \"Other\" to avoid overfitting on rare categories.\n",
    "o\tI scaled the features using StandardScaler to help the model learn more effectively.\n",
    "Summary\n",
    "\n",
    "•\tOverall Results:\n",
    "o\tThe deep learning model achieved a 79% accuracy on the test data. While this is good, there’s still potential to improve the model’s performance.\n",
    "\n",
    "•\tRecommendation for a Different Model:\n",
    "o\tA Random Forest Classifier is an excellent alternative for this scenario. It effectively handles both categorical and numerical data while being less prone to overfitting. Compared to neural networks, this model is easier to tune and interpret, often yielding superior results. Random Forests excel with structured data and can help identify the most significant features for predicting outcomes. Additionally, they do not require feature scaling, which streamlines the modeling process.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
